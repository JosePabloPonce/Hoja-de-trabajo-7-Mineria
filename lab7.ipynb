{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as smd\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sb\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.diagnostic as diag\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score,precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"train.csv\", encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se puede observar todas las columnas que tiene el dataframe de los datos proporcionados por train.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra la cantidad de datos, siendo 81 columnas con 1460 filas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene una estadistica descriptiva de los datos para resumir la medida de tendencia central y la distribucion de los datos. Se puede observar que el precio mas bajo de casas es de 34900, el precio mas alto de una casa es de 755000, la media es de 190821 y en los percentiles el 25% es de 129975, el 50% es de 163000 y el 75% es de 214000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se determina los tipos de datos que hay siendo 35 de tipo int64, 3 de tipo float64 y 43 de tipo object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un mapa de calor para ver la correlacion de las variables y empezar a descartar y seleccionar las de utilidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacion_datos = datos.corr()\n",
    "f, ax = plt.subplots(figsize=(45, 13))\n",
    "sb.heatmap(correlacion_datos, vmax=1,square=True, linewidths=.5)\n",
    "plt.title(\"Correlacion entre variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen las variables de interes que tengan una correlacion mayor a 0.5 con Sale Price, pudiendo notar que YearRemodAdd, solo se correlaciona con SalePrice con una variable de correlacion de 0.51 y no muestra correlacion muy debil con el resto de variables, por lo que se descarta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_correlacionados = correlacion_datos.index[(correlacion_datos[\"SalePrice\"])>0.5]\n",
    "plt.figure(figsize = (11,8))\n",
    "plt.title(\"Correlacion mayor a 0.5 con SalePrice\")\n",
    "g = sb.heatmap(datos[datos_correlacionados].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras analizar las variables en el mapa de calor, se descartan las que no aportan mayor informacion al compararlo con otras variables que no sean SalePrice. Asi mismo se realiza un diagrama de dispersion con dichas variables, notando que la correlacion es positiva y debilmente positiva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(datos,vars=[\"SalePrice\",\"GarageArea\",\"GarageCars\",\"TotRmsAbvGrd\",\"FullBath\",\"GrLivArea\",\"1stFlrSF\", \"TotalBsmtSF\", \"YearBuilt\", \"OverallQual\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use los mismos conjuntos de entrenamiento y prueba para probar el algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore los datos y explique las transformaciones que debe hacerle para generar un modelo de máquinas vectoriales de soporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use como variable respuesta la variable categórica que especifica si la casa es barata, media o cara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Genere varios (más de 2) modelos de SVM con diferentes kernels y distintos valores en los parámetros c, gamma y d (en caso de que utilice el polinomial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Use los modelos para predecir el valor de la variable respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Haga las matrices de confusión respectivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Compare  los  resultados  obtenidos  con  los  diferentes  modelos  que  hizo  en  cuanto  a efectividad,  tiempo  de  procesamiento  y  equivocaciones  (donde  el  algoritmo  se  equivocó más, donde se equivocó menos y la importancia que tienen los errores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Compare  la  eficiencia  del  mejor  modelo  de  SVM  con  los  resultados  obtenidos  en  los algoritmos de las hojas de trabajo anteriores que usen la misma variable respuesta (árbol de decisión y random forest, naive bayes). ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Genere un informe de los resultados y las explicaciones."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
